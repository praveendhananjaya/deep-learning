{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNA8bGzKN3UHspUlbcJUTyv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveendhananjaya/deep-learning/blob/main/IMDB/IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPdz_jxhhAGf",
        "outputId": "2dc10471-98fb-4aa6-d5d5-83dd8e7bd0ce"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
        "num_words=10000)\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm43n1-XE5Lk",
        "outputId": "d9006fd0-d832-4eaf-ec54-ddfc8c7688e4"
      },
      "source": [
        "len(train_data[10])\n",
        "\n",
        "INDEX_FROM=3   # word index offset\n",
        "\n",
        "word_to_id = imdb.get_word_index()\n",
        "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
        "word_to_id[\"<PAD>\"] = 0\n",
        "word_to_id[\"<START>\"] = 1\n",
        "word_to_id[\"<UNK>\"] = 2\n",
        "word_to_id[\"<UNUSED>\"] = 3\n",
        "\n",
        "id_to_word = {value:key for key,value in word_to_id.items()}\n",
        "print(' '.join(id_to_word[id] for id in train_data[2] ))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<START> this has to be one of the worst films of the 1990s when my friends i were watching this film being the target audience it was aimed at we just sat watched the first half an hour with our jaws touching the floor at how bad it really was the rest of the time everyone else in the theatre just started talking to each other leaving or generally crying into their popcorn that they actually paid money they had <UNK> working to watch this feeble excuse for a film it must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can't get across how <UNK> this is to watch save yourself an hour a bit of your life\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITa4ENqbJ7ck"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "  results = np.zeros((len(sequences), dimension))\n",
        "  for i, sequence in enumerate(sequences):\n",
        "    results[i, sequence] = 1.\n",
        "  return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVLk6ndfSWjS"
      },
      "source": [
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I7OgtU92816"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyWvXUG73M3m"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNcuPbBO3Pa9"
      },
      "source": [
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D10LfRqL3qlb",
        "outputId": "36bb2d9a-4a4f-436d-86c8-3c57b3329075"
      },
      "source": [
        "\n",
        "history = model.fit(partial_x_train,\n",
        "            partial_y_train,\n",
        "            epochs=20,\n",
        "            batch_size=512,\n",
        "            validation_data=(x_val, y_val))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 4s 36ms/step - loss: 0.5795 - accuracy: 0.7103 - val_loss: 0.4066 - val_accuracy: 0.8331\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.3152 - accuracy: 0.8987 - val_loss: 0.3003 - val_accuracy: 0.8845\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2149 - accuracy: 0.9354 - val_loss: 0.2801 - val_accuracy: 0.8887\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.1676 - accuracy: 0.9451 - val_loss: 0.2870 - val_accuracy: 0.8853\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.1406 - accuracy: 0.9583 - val_loss: 0.2866 - val_accuracy: 0.8844\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.1114 - accuracy: 0.9682 - val_loss: 0.3094 - val_accuracy: 0.8801\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.0944 - accuracy: 0.9741 - val_loss: 0.3198 - val_accuracy: 0.8798\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.0811 - accuracy: 0.9767 - val_loss: 0.3333 - val_accuracy: 0.8796\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0601 - accuracy: 0.9860 - val_loss: 0.3549 - val_accuracy: 0.8798\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0524 - accuracy: 0.9866 - val_loss: 0.3857 - val_accuracy: 0.8756\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0404 - accuracy: 0.9923 - val_loss: 0.4168 - val_accuracy: 0.8765\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0356 - accuracy: 0.9913 - val_loss: 0.4479 - val_accuracy: 0.8762\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.0253 - accuracy: 0.9956 - val_loss: 0.4782 - val_accuracy: 0.8753\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.0201 - accuracy: 0.9975 - val_loss: 0.5075 - val_accuracy: 0.8732\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0171 - accuracy: 0.9978 - val_loss: 0.5633 - val_accuracy: 0.8694\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0145 - accuracy: 0.9983 - val_loss: 0.5800 - val_accuracy: 0.8675\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0098 - accuracy: 0.9991 - val_loss: 0.6107 - val_accuracy: 0.8681\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0068 - accuracy: 0.9998 - val_loss: 0.6500 - val_accuracy: 0.8680\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0081 - accuracy: 0.9988 - val_loss: 0.6800 - val_accuracy: 0.8671\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.0047 - accuracy: 0.9996 - val_loss: 0.7116 - val_accuracy: 0.8656\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}